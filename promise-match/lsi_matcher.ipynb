{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "from konlpy.corpus import kobill, kolaw\n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "stopwords = \"수 년 등 및 몇 중 네이버 뉴스\".split()\n",
    "stopwords += \"공급 설치 조성 운영 실행 설립 확대 건설 제공 사업 실시 지원 검토 육성 추진 유치 강화 개선 구축 마련 확충 실시 개선 해소\".split()\n",
    "stopwords = set(stopwords)\n",
    "\n",
    "pos = lambda d: ['/'.join(p) for p in twitter.pos(d, stem=True, norm=True) if p[0] not in stopwords and p[1] in ('Noun', 'Verb', 'Adjective')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 31.2 ms, total: 1.36 s\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts_kobill = [pos(kobill.open(i).read()) for i in kobill.fileids()]\n",
    "texts_kolaw = [pos(kolaw.open(i).read()) for i in kolaw.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 s, sys: 30.2 ms, total: 1.76 s\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "texts = []\n",
    "\n",
    "with open('jisa_tagged.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    for voting_district in data:\n",
    "        promises = voting_district['promises']\n",
    "        for p in promises:\n",
    "            texts.append((p['title'], pos(p['title'])))\n",
    "\n",
    "texts_promises = [text[1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "# Create dictionary\n",
    "corpus = texts_kobill + texts_kolaw + texts_promises\n",
    "#corpus = texts_promises\n",
    "logging.info('Dictionary from %d documents' % len(corpus))\n",
    "dictionary_ko = corpora.Dictionary(corpus)\n",
    "# Filter terms that occur in more than 2% of the documents\n",
    "dictionary_ko.filter_extremes(no_below=0, no_above=0.02)\n",
    "# Save for later use\n",
    "dictionary_ko.save('ko.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-21 18:02:45,384 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 984 ms, sys: 74.5 ms, total: 1.06 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim import similarities\n",
    "\n",
    "num_topics = 100\n",
    "\n",
    "# Generate Lsi model for promise text corpus\n",
    "corpus = [dictionary_ko.doc2bow(text) for text in texts_promises]\n",
    "# Train Lsi model\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary_ko, num_topics=num_topics)\n",
    "# Transform corpus to LSI space and index it\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to 동북아 대도시 대기환경협의체 구성 및 대기개선 노하우 공유 (동북아/Noun 대도시/Noun 대기/Noun 환경/Noun 협의/Noun 체/Noun 구성/Noun 대기/Noun 노하우/Noun 공유/Noun)\n",
      "0.92 - 영남권대기환경청 설립 추진\n",
      "0.75 - 노사민정협의체 활성화로 상생기업 환경 구축\n",
      "0.70 - 문화거버넌스 구성 및 운영\n",
      "Most similar to 초미세먼지 노출 예방 시스템 구축 (초미세먼지/Noun 노출/Noun 예방/Noun 시스템/Noun)\n",
      "0.89 - 공유경제 지원시스템 구축\n",
      "0.87 - 지역 공기질 측정 및 실시간 공개시스템 구축\n",
      "0.86 - 9-1 대중교통 시스템의 획기적 개선 (촘촘한 노선 구축, 심야버스 운행 등)\n",
      "Most similar to 생활권 주변 10분거리 공원 조성 (생활권/Noun 주변/Noun 분/Noun 거리/Noun 공원/Noun)\n",
      "0.92 - 공원과 산책로 칼로리 게시판 후원합니다\n",
      "0.92 - 시민체감형 도시공원, 녹지관리\n",
      "0.92 - 대통령 기념공원 조성\n",
      "Most similar to 유아숲 체험장 50개소 설치 등 생애주기별 힐링공원 조성 (유아/Noun 숲/Noun 체험/Noun 개다/Verb 생애/Noun 주기/Noun 별/Noun 힐링/Noun 공원/Noun)\n",
      "0.81 - 생애주기형 도시숲 조성\n",
      "0.77 - 힐링 아일랜드 조성\n",
      "0.73 - 도시숲 확대\n",
      "Most similar to 걷고 싶은 서울길’ 완성 (걷다/Verb 싶다/Verb 서울/Noun 길/Noun 완성/Noun)\n",
      "0.94 - 서울공예박물관’ 건립\n",
      "0.94 - 서울시네마테크’ 건립\n",
      "0.94 - 서울전역 와이파이존 구축\n",
      "Most similar to 학교 80개교와 사회복지시설에 ‘싱싱텃밭’ 조성 (학교/Noun 개교/Noun 사회/Noun 복지/Noun 시설/Noun 싱싱/Noun 텃밭/Noun)\n",
      "0.99 - 50+ 경험과 노하우를 배우는 온라인 인생학교(TED) 조성\n",
      "0.89 - 초.중,특수학교 친환경 학교급식 확대\n",
      "0.83 - 우리아이들안전을위한학교앞차량통행제한\n",
      "Most similar to 생태 친화적 가로수길 ‘우리동네 산책길’ 조성 (생태/Noun 친/Noun 적/Noun 가로수길/Noun 우리동네/Noun 산책길/Noun)\n",
      "0.86 - 여성친화도시 조성\n",
      "0.86 - 시민친화적 구덕운동장 재개발\n",
      "0.83 - 외국인 친화형 메뉴판과 라벨\n",
      "Most similar to 시민참여형 소규모 햇빛발전소 확대 (시민/Noun 참여/Noun 소규모/Noun 햇빛/Noun 발전소/Noun)\n",
      "0.98 - 남성육아휴직 참여 및 지원 확대\n",
      "0.89 - 평생교육‧직업훈련 지원 및 참여기회 확대\n",
      "0.89 - 더불어 시민과 함께하는 시민참여플랫폼 구축 운영\n",
      "Most similar to 태양광 설치비’ 장기 저금리 융자지원 (태양광/Noun 비/Noun 장기/Noun 금리/Noun 융자/Noun)\n",
      "0.83 - 경로당 운영비 확대 지원\n",
      "0.76 - 중․고 입학생 교복구입비 지원\n",
      "0.73 - 주안 재정비 촉진지구 활성화\n",
      "Most similar to 녹색기업 지원을 통한 좋은 에너지 일터 조성 (녹색/Noun 기업/Noun 통한/Noun 좋다/Adjective 에너지/Noun 일터/Noun)\n",
      "0.63 - 13-2수도권 성장·유망 기업 유치를 통한 일자리 창출\n",
      "0.63 - 자립형 강소(벤처)기업 육성 및 지원\n",
      "0.62 - 대기업 및 글로벌기업 유치\n",
      "Most similar to 서울형 녹색기술 R&D 지원과 전문인력 양성 확대 (서울/Noun 녹색/Noun 기술/Noun 전문/Noun 인력/Noun 양성/Noun)\n",
      "0.82 - MICE산업 육성을 위하여 ‘전문인력 양성강화’ 및 ‘국내 컨벤션의 국제화 지원’ 등 실시\n",
      "0.70 - 문화예술 전문인력 양성 및 배치\n",
      "0.67 - 출산전후 휴가·육아휴직 「대체인력뱅크」 운영\n"
     ]
    }
   ],
   "source": [
    "def find_similar(tagged_text, similarity_threshold=None):\n",
    "    # Convert text to bag of words\n",
    "    vec_bow = dictionary_ko.doc2bow(tagged_text)\n",
    "    # Convert the query to LSI space\n",
    "    vec_lsi = lsi[vec_bow]\n",
    "    # Perform a similarity query against the corpus\n",
    "    sims = enumerate(index[vec_lsi])\n",
    "    if similarity_threshold:\n",
    "        sims = filter(lambda item: item[1] >= similarity_threshold, sims)\n",
    "    # Return the similarities sorted by descending score\n",
    "    return sorted(sims, key=lambda item: -item[1])\n",
    "    \n",
    "# Try to match a few existing documents\n",
    "for text in texts[100:111]:\n",
    "    sims = find_similar(text[1])\n",
    "    print(\"Most similar to %s (%s)\" % (text[0], ' '.join(text[1])))\n",
    "    for key, score in sims[1:4]:\n",
    "        key = int(key)\n",
    "        print('%.2f - %s' % (score, texts[key][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches per document: max 33, min 0, mean 9.83, median 9\n",
      "55 documents didn't match with themself as their best match\n",
      "  but 43 of them matched at pos 1.\n",
      "124 (5%) with 0 matches\n",
      "CPU times: user 9.14 s, sys: 208 ms, total: 9.35 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find similarities of all documents with each other and see how many matches higher than x score there are\n",
    "# Used to figure out a threshold that regards enough documents as matched\n",
    "threshold = 0.65\n",
    "counts = []\n",
    "counts_self_no_match = []\n",
    "for idx, text in enumerate(texts):\n",
    "    similarities = np.array(find_similar(text[1]))\n",
    "    # Remove self-similarity\n",
    "    id_idx = np.where(similarities[:, 0]==idx)[0][0]\n",
    "    similarities = np.delete(similarities, id_idx, axis=0)\n",
    "    # Record when self wasn't the best match (it is usally the 2nd best in these cases)\n",
    "    if id_idx != 0:\n",
    "        counts_self_no_match.append((idx, id_idx))\n",
    "    # Count number of docs with similarity >= threshold\n",
    "    count = np.sum(similarities[:,1]>=threshold)  # Skip the first row since it will be the queried text itself\n",
    "    counts.append(count)\n",
    "\n",
    "counts = np.array(counts)\n",
    "counts_self_no_match = np.array(counts_self_no_match)\n",
    "print('Number of matches per document: max %d, min %d, mean %.2f, median %d' % (np.max(counts), np.min(counts), np.mean(counts), np.median(counts)))\n",
    "print('%d documents didn\\'t match with themself as their best match' % (len(counts_self_no_match)))\n",
    "print('  but %d of them matched at pos 1.' % (np.sum(counts_self_no_match[:,1]==1)))\n",
    "\n",
    "no_match_count = np.sum(counts==0)\n",
    "print('%d (%d%%) with 0 matches' % (no_match_count, 100*no_match_count/len(counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to 임대주택\n",
      " 1. 1.00 - 소정면 임대주택 건설\n",
      " 2. 0.86 - 신혼부부‧학생‧일인가구 등 수요대응형 주택공급 및 임대주택 지속 공급\n",
      " 3. 0.82 - 민간임대주택 지원을 위한 국민주택기금 및 이자지원 확대\n",
      " 4. 0.76 - 다세대주택 범죄자! ‘특수 형광물질’이 다 잡아냅니다\n",
      " 5. 0.76 - 전용면적 30~60m² 소형주택 20만호 공급 지원\n",
      " 6. 0.75 - 노후 주택 녹슨 상수도관 개량 지원\n",
      " 7. 0.72 - 공동체 주택건설\n",
      "Most similar to  임대주택 등록하면 세금·건보료 감면…2020년 등록 의무화 검토\n",
      " 1. 0.82 - 소정면 임대주택 건설\n",
      " 2. 0.75 - 신혼부부‧학생‧일인가구 등 수요대응형 주택공급 및 임대주택 지속 공급\n",
      " 3. 0.72 - 민간임대주택 지원을 위한 국민주택기금 및 이자지원 확대\n",
      " 4. 0.70 - 노후 주택 녹슨 상수도관 개량 지원\n",
      " 5. 0.70 - 전용면적 30~60m² 소형주택 20만호 공급 지원\n",
      " 6. 0.69 - 공동체 주택건설\n",
      " 7. 0.68 - 주택임대차 표준계약서 의무사용 법제화 건의\n",
      " 8. 0.68 - 다세대주택 범죄자! ‘특수 형광물질’이 다 잡아냅니다\n"
     ]
    }
   ],
   "source": [
    "# Try some queries that don't match existing documents\n",
    "\n",
    "def match(title):\n",
    "    print(\"Most similar to %s\" % title)\n",
    "    threshold = 0.65\n",
    "    for posi, item in enumerate(find_similar(pos(title), threshold)):\n",
    "        key = int(item[0])\n",
    "        score = item[1]\n",
    "        print('%2d. %.2f - %s' % (posi+1, score, texts[key][0]))\n",
    "\n",
    "match('임대주택')\n",
    "match(' 임대주택 등록하면 세금·건보료 감면…2020년 등록 의무화 검토')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
